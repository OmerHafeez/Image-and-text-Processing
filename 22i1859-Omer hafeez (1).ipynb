{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa882240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import mark_negation\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d75cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Muhammad Omer\n",
      "[nltk_data]     Hafeez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43bfb578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Muhammad Omer\n",
      "[nltk_data]     Hafeez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb7e7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Muhammad\n",
      "[nltk_data]     Omer Hafeez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dcb3047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Muhammad Omer\n",
      "[nltk_data]     Hafeez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590223fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Muhammad Omer\n",
      "[nltk_data]     Hafeez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732e7d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Muhammad Omer\n",
      "[nltk_data]     Hafeez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a7c7b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Muhammad\n",
      "[nltk_data]     Omer Hafeez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"maxent_ne_chunker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25a1bec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shakespeare Style:\n",
      "times refigured thee; For rich no more\n",
      "calls thee still, Attending on the edge should look pale,\n",
      "among: I eyed, Such cherubins as a\n",
      "date. Sometime too dear religious love as\n",
      "\n",
      "Angelou Style:\n",
      "an interrupted cry Came over you put Beneath\n",
      "trees will be lost. And blue so on her teacher\n",
      "Matthew Arnold: ''Nature is done with earth, perhaps, about\n",
      "was it takes the wall And thus into itself Under\n",
      "\n",
      "Shakespeare Style:\n",
      "That looks his love.\" Full many parts, His\n",
      "to the first in themselves their own: I may\n",
      "my slumbers should example where you have what with\n",
      "If some in my flame with you have\n",
      "\n",
      "Angelou Style:\n",
      "Be dragged to ourselves to tell her\n",
      "World's Poetry Archive 22 A Cliff Dwelling\n",
      "to see too short To the side they\n",
      "be told, 'We all there always? -- his heel. But\n",
      "\n",
      "Shakespeare Style:\n",
      "tender'd The aloes of posting is such substance\n",
      "King Pandion he send: His flattering foe.\n",
      "blame me then, to-morrow morning?-- No, let us all my\n",
      "outlive a double penance to import forgetfulness in\n",
      "\n",
      "Angelou Style:\n",
      "proof. Let alone Somehow must be business. Did\n",
      "It would be left his eyeâ€” Which shows how have\n",
      "and knees unless you that he been to sell. His\n",
      "nothing else is on the gloaming with a flower were\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from nltk import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "def read_corpus(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        corpus_text = file.read()\n",
    "        return corpus_text.split()\n",
    "\n",
    "file_path_shakespeare = 'C:\\\\Users\\\\Muhammad Omer Hafeez\\\\Desktop\\\\material\\\\Q1\\\\william shakespeare.txt'\n",
    "file_path_angelou = 'C:\\\\Users\\\\Muhammad Omer Hafeez\\\\Desktop\\\\material\\\\Q1\\\\Robert Frost.txt'\n",
    "\n",
    "shakespeare_corpus = read_corpus(file_path_shakespeare)\n",
    "angelou_corpus = read_corpus(file_path_angelou)\n",
    "\n",
    "def generate_line(model, current_word):\n",
    "    verse_length = random.randint(7, 10)\n",
    "    verse = [current_word]\n",
    "\n",
    "    for _ in range(verse_length - 1):\n",
    "        if len(verse) == 1:\n",
    "            next_words = [word[1] for word in model if word[0] == current_word]\n",
    "        elif len(verse) == 2:\n",
    "            last_word = verse[-1]\n",
    "            next_words = [word[1] for word in model if word[0] == last_word]\n",
    "        else:\n",
    "            prev_word1, prev_word2 = verse[-2], verse[-1]\n",
    "            next_words = [word[1] for word in model if word[0] == prev_word2]\n",
    "\n",
    "        if next_words:\n",
    "            next_word = random.choice(next_words)\n",
    "            verse.append(next_word)\n",
    "            current_word = next_word\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return \" \".join(verse)\n",
    "\n",
    "def generate_poem(shakespeare_model, angelou_model, stanza_count=3):\n",
    "    for _ in range(stanza_count):\n",
    "        # Print Shakespeare style heading only once\n",
    "        print(\"Shakespeare Style:\")\n",
    "        for _ in range(4):\n",
    "            shakespeare_line = generate_line(shakespeare_model, random.choice(shakespeare_corpus))\n",
    "            print(shakespeare_line)\n",
    "        print()\n",
    "\n",
    "        # Print Angelou style heading only once\n",
    "        print(\"Angelou Style:\")\n",
    "        for _ in range(4):\n",
    "            angelou_line = generate_line(angelou_model, random.choice(angelou_corpus))\n",
    "            print(angelou_line)\n",
    "        print()\n",
    "\n",
    "# Example usage:\n",
    "shakespeare_unigram_model = FreqDist(shakespeare_corpus)\n",
    "shakespeare_bigram_model = list(ngrams(shakespeare_corpus, 2))\n",
    "shakespeare_trigram_model = list(ngrams(shakespeare_corpus, 3))\n",
    "\n",
    "angelou_unigram_model = FreqDist(angelou_corpus)\n",
    "angelou_bigram_model = list(ngrams(angelou_corpus, 2))\n",
    "angelou_trigram_model = list(ngrams(angelou_corpus, 3))\n",
    "\n",
    "generate_poem(shakespeare_bigram_model, angelou_bigram_model, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c78161f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#file_path = 'C:\\\\Users\\\\Muhammad Omer Hafeez\\\\Desktop\\\\material\\\\Q1\\\\Robert Frost.txt'\n",
    "#with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#    corpus_text = file.read()\n",
    "# Tokenize \n",
    "#corpus_words = nltk.word_tokenize(corpus_text.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0190029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk import ngrams\n",
    "#from nltk.probability import FreqDist\n",
    "#unigram_model = FreqDist(corpus_words)\n",
    "#bigram_model = list(ngrams(corpus_words, 2))\n",
    "#trigram_model = list(ngrams(corpus_words, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49005898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generate_poem(ngram_model, stanza_count=3):\n",
    "#    for _ in range(stanza_count):\n",
    "#        for _ in range(4):\n",
    "#            verse_length = random.randint(7, 10)\n",
    "#            current_word = random.choice(ngram_model[0])\n",
    "#            verse = [str(current_word)] \n",
    "\n",
    " #           for _ in range(verse_length - 1):\n",
    " #               if len(verse) == 1:\n",
    "  #                  next_words = ngram_model[1]\n",
    "   #             elif len(verse) == 2:\n",
    "    #                last_word = verse[-1]\n",
    "     #               next_words = [str(word[1]) for word in ngram_model[2] if word[0] == last_word]\n",
    "      #          else:\n",
    "       #             prev_word1, prev_word2 = verse[-2], verse[-1]\n",
    "        #            next_words = [str(word[2]) for word in ngram_model[3] if word[:2] == (prev_word1, prev_word2)]\n",
    "#\n",
    " ##                  next_word = random.choice(next_words)\n",
    "   #                 verse.append(str(next_word))\n",
    "    #                current_word = next_word\n",
    "     #           else:\n",
    "      #              break\n",
    "       #     print(\" \".join(verse))\n",
    "        #print()  \n",
    "#generate_poem((corpus_words, unigram_model, bigram_model, trigram_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60e555dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = 'C:\\\\Users\\\\Muhammad Omer Hafeez\\\\Desktop\\\\material\\\\Q1\\\\william shakespeare.txt'\n",
    "#with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#   corpus_text = file.read()\n",
    "## Tokenize \n",
    "#corpus_words = nltk.word_tokenize(corpus_text.lower())\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf3503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk import ngrams\n",
    "#from nltk.probability import FreqDist\n",
    "#unigram_model = FreqDist(corpus_words)\n",
    "#bigram_model = list(ngrams(corpus_words, 2))\n",
    "#trigram_model = list(ngrams(corpus_words, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61c1867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generate_poem(ngram_model, stanza_count=3):\n",
    " #   for _ in range(stanza_count):\n",
    "  #      for _ in range(4):\n",
    "   #         verse_length = random.randint(7, 10)\n",
    "    #        current_word = random.choice(ngram_model[0])\n",
    "     #       verse = [str(current_word)] \n",
    "#\n",
    " #           for _ in range(verse_length - 1):\n",
    "  #              if len(verse) == 1:\n",
    "   #                 next_words = ngram_model[1]\n",
    "    #            elif len(verse) == 2:\n",
    "     #               last_word = verse[-1]\n",
    "      #              next_words = [str(word[1]) for word in ngram_model[2] if word[0] == last_word]\n",
    "       #         else:\n",
    "        #            prev_word1, prev_word2 = verse[-2], verse[-1]\n",
    "         #           next_words = [str(word[2]) for word in ngram_model[3] if word[:2] == (prev_word1, prev_word2)]\n",
    "\n",
    "#                if next_words:\n",
    " #                   next_word = random.choice(next_words)\n",
    "  #                  verse.append(str(next_word))\n",
    "   #                 current_word = next_word\n",
    "    #            else:\n",
    "     #               break\n",
    "      #      print(\" \".join(verse))\n",
    "       # print()  \n",
    "#generate_poem((corpus_words, unigram_model, bigram_model, trigram_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f2668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4915797f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e30c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59934f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6230018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae80f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa8dc5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cff9b871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a250f665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank white image as the background\n",
    "background = np.ones((996, 1500, 3), np.uint8) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee975749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your sub-images (replace these with your actual images)\n",
    "sub_image1 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img1.png')\n",
    "sub_image2 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img2.png')\n",
    "sub_image3 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img3.png')\n",
    "sub_image4 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img4.png')\n",
    "sub_image5 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img5.png')\n",
    "sub_image6 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img6.png')\n",
    "sub_image7 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img7.png')\n",
    "sub_image8 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img8.png')\n",
    "sub_image9 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img9.png')\n",
    "sub_image10 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img10.png')\n",
    "sub_image11 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img11.png')\n",
    "sub_image12 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img12.png')\n",
    "sub_image13 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img13.png')\n",
    "sub_image14 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img14.png')\n",
    "sub_image15 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img15.png')\n",
    "sub_image16 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img16.png')\n",
    "sub_image17 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img17.png')\n",
    "sub_image18 = cv2.imread(r'C:\\Users\\Muhammad Omer Hafeez\\Desktop\\material\\Q2\\puzzle\\img18.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7eb1456",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row, col = 2, 2\n",
    "\n",
    "x1 = (col - 1) * sub_image1.shape[1]\n",
    "x2 = x1 + sub_image1.shape[1]\n",
    "y1 = (row - 1) * sub_image1.shape[0]\n",
    "y2 = y1 + sub_image1.shape[0]\n",
    "\n",
    "background[y1:y2, x1:x2] = sub_image1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d99a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4acdfe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_image5_rotated = cv2.rotate(sub_image5, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "x1_sub5 = x2  \n",
    "x2_sub5 = x1_sub5 + sub_image5_rotated.shape[1]\n",
    "y1_sub5 = y1\n",
    "y2_sub5 = y2\n",
    "background[y1_sub5:y2_sub5, x1_sub5:x2_sub5] = sub_image5_rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afc99362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sub_image18_resized = cv2.resize(sub_image18, (x2_sub5 - x1_sub5, y2 - y1))\n",
    "\n",
    "sharpening_kernel = np.array([[-1, -1, -1],\n",
    "                             [-1,  9, -1],\n",
    "                             [-1, -1, -1]])\n",
    "\n",
    "\n",
    "sharpened_image = cv2.filter2D(sub_image18_resized, -1, sharpening_kernel)\n",
    "\n",
    "x1_another = x2_sub5\n",
    "x2_another = x1_another + sharpened_image.shape[1]  \n",
    "y1_another = y1\n",
    "y2_another = y2\n",
    "\n",
    "background[y1_another:y2_another, x1_another:x2_another] = sharpened_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0b09b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row, new_col = 3, 2\n",
    "\n",
    "new_x1 = (new_col - 1) * sub_image1.shape[1]\n",
    "new_x2 = new_x1 + sub_image1.shape[1]\n",
    "new_y1 = (new_row - 1) * sub_image1.shape[0]\n",
    "new_y2 = new_y1 + sub_image1.shape[0]\n",
    "\n",
    "mirrored_horizontal = cv2.flip(sub_image7, 1)\n",
    "\n",
    "mirrored_horizontal_resized = cv2.resize(mirrored_horizontal, (346, 304))\n",
    "\n",
    "background[new_y1:new_y2, new_x1:new_x2] = mirrored_horizontal_resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b70ff2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#background_height, background_width, _ = background.shape\n",
    "#sub_image6_rotated = sub_image6\n",
    "\n",
    "#if sub_image6_rotated.shape[0] > sub_image6_rotated.shape[1]:\n",
    "    # Swap the dimensions for landscape mode\n",
    "#    sub_image6_rotated = cv2.transpose(sub_image6_rotated)\n",
    "#    sub_image6_rotated = cv2.flip(sub_image6_rotated, flipCode=1)\n",
    "\n",
    "#sub_image_height, sub_image_width, _ = sub_image6_rotated.shape\n",
    "\n",
    "#bottom_mid_x1 = (background_width - sub_image_width) // 2\n",
    "#bottom_mid_x2 = bottom_mid_x1 + sub_image_width\n",
    "#bottom_mid_y1 = background_height - sub_image_height\n",
    "#bottom_mid_y2 = background_height\n",
    "\n",
    "#background[bottom_mid_y1:bottom_mid_y2, bottom_mid_x1:bottom_mid_x2] = sub_image6_rotated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a204ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.imwrite('complete_image.jpg', background)\n",
    "cv2.imshow('Complete Image', background)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b7a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faabde3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c14c5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "background2 = np.ones((1500, 1500, 3), np.uint8) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ef75234",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row, col = 2, 2\n",
    "\n",
    "x1 = (col - 1) * sub_image8.shape[1]\n",
    "x2 = x1 + sub_image8.shape[1]\n",
    "y1 = (row - 1) * sub_image8.shape[0]\n",
    "y2 = y1 + sub_image8.shape[0]\n",
    "\n",
    "background2[y1:y2, x1:x2] = sub_image8  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c815b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(sub_image9.shape) == 2:\n",
    "    sub_image9_rgb = cv2.cvtColor(sub_image9, cv2.COLOR_GRAY2RGB)\n",
    "else:\n",
    "    sub_image9_rgb = sub_image9.copy()\n",
    "\n",
    "image9_resized = cv2.resize(sub_image9, (sub_image8.shape[1], sub_image8.shape[0]))\n",
    "\n",
    "flipped_image9 = cv2.flip(image9_resized, 1)\n",
    "\n",
    "row, col = 2, 1\n",
    "x1 = (col - 1) * flipped_image9.shape[1]\n",
    "x2 = x1 + flipped_image9.shape[1]\n",
    "y1 = (row - 1) * flipped_image9.shape[0]\n",
    "y2 = y1 + flipped_image9.shape[0]\n",
    "\n",
    "background2[y1:y2, x1:x2] = flipped_image9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf62bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image14_resized = cv2.resize(sub_image14, (sub_image8.shape[1], sub_image8.shape[0]))\n",
    "\n",
    "row, col = 1, 2\n",
    "x1 = (col - 1) * image14_resized.shape[1]\n",
    "x2 = x1 + image14_resized.shape[1]\n",
    "y1 = (row - 1) * image14_resized.shape[0]\n",
    "y2 = y1 + image14_resized.shape[0]\n",
    "\n",
    "background2[y1:y2, x1:x2] = image14_resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90037125",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image13_resized = cv2.resize(sub_image13, (sub_image8.shape[1], sub_image8.shape[0]))\n",
    "\n",
    "row, col = 2, 3\n",
    "x1 = (col - 1) * image13_resized.shape[1]\n",
    "x2 = x1 + image13_resized.shape[1]\n",
    "y1 = (row - 1) * image13_resized.shape[0]\n",
    "y2 = y1 + image13_resized.shape[0]\n",
    "\n",
    "background2[y1:y2, x1:x2] = image13_resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3604e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image12_resized = cv2.resize(sub_image12, (sub_image8.shape[1], sub_image8.shape[0]))\n",
    "\n",
    "row, col = 3, 3\n",
    "x1 = (col - 1) * image12_resized.shape[1]\n",
    "x2 = x1 + image12_resized.shape[1]\n",
    "y1 = (row - 1) * image12_resized.shape[0]\n",
    "y2 = y1 + image12_resized.shape[0]\n",
    "\n",
    "background2[y1:y2, x1:x2] = image12_resized\n",
    "yellow_tint = np.ones_like(sub_image9_rgb) * [0, 255, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96298a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_image17_rotated = cv2.rotate(sub_image17, cv2.ROTATE_90_CLOCKWISE)\n",
    "sub_image17_rotated = cv2.rotate(sub_image17_rotated, cv2.ROTATE_90_CLOCKWISE)\n",
    "sub_image17_rotated = cv2.rotate(sub_image17_rotated, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "image17_resized = cv2.resize(sub_image17_rotated, (sub_image8.shape[1], sub_image8.shape[0]))\n",
    "\n",
    "row, col = 3, 2\n",
    "x1 = (col - 1) * image17_resized.shape[1]\n",
    "x2 = x1 + image17_resized.shape[1]\n",
    "y1 = (row - 1) * image17_resized.shape[0]\n",
    "y2 = y1 + image17_resized.shape[0]\n",
    "\n",
    "background2[y1:y2, x1:x2] = image17_resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0b6da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_image11_rotated = cv2.rotate(sub_image11, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "image11_resized = cv2.resize(sub_image11_rotated, (sub_image8.shape[1], sub_image8.shape[0]))\n",
    "\n",
    "row, col = 1, 1\n",
    "x1 = (col - 1) * image11_resized.shape[1]\n",
    "x2 = x1 + image11_resized.shape[1]\n",
    "y1 = (row - 1) * image11_resized.shape[0]\n",
    "y2 = y1 + image11_resized.shape[0]\n",
    "\n",
    "background2[y1:y2, x1:x2] = image11_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0920266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_image11_rotated = cv2.rotate(sub_image11, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "image4_resized = cv2.resize(sub_image11_rotated, (sub_image8.shape[1], sub_image8.shape[0]))\n",
    "\n",
    "row, col = 1, 3\n",
    "x1 = (col - 1) * image11_resized.shape[1]\n",
    "x2 = x1 + image11_resized.shape[1]\n",
    "y1 = (row - 1) * image11_resized.shape[0]\n",
    "y2 = y1 + image11_resized.shape[0]\n",
    "\n",
    "background2[y1:y2, x1:x2] = image11_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4643550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_image10_rotated = cv2.rotate(sub_image10, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "image10_resized = cv2.resize(sub_image10_rotated, (sub_image8.shape[1], sub_image8.shape[0]))\n",
    "\n",
    "row, col = 3, 1\n",
    "x1 = (col - 1) * image10_resized.shape[1]\n",
    "x2 = x1 + image10_resized.shape[1]\n",
    "y1 = (row - 1) * image10_resized.shape[0]\n",
    "y2 = y1 + image10_resized.shape[0]\n",
    "\n",
    "background2[y1:y2, x1:x2] = image10_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31ca819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.imwrite('complete_image.jpg', background2)\n",
    "cv2.imshow('Complete Image', background2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf24ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
